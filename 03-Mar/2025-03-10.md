# 날짜: 2025-03-10

## 새로 배운 내용
### 주제 1: NLP
- 번역, 감정 분석, 키워드 추출, 채팅봇 등 자연어를 처리하는 작업
- 컴퓨터가 자연어를 처리하기 위해, 단어의 벡터화가 필요하다
- Bag of Words(BoW): 단어들의 문장 내 등장 빈도를 벡터로 표현
  tf-idf: 다른 문서에서의 빈도도 확인, 항상 자주 등장하는 관사 등에 패널티 부여
#### Word2Vec
- 단어의 벡터화를 One-hot이 아닌, 연산 가능한 방식으로 이루어 낸 방법
- Continuous BoW: 주변 단어 벡터를 보고 중심 단어 벡터를 예측하도록 학습
- Skip-gram: 중심 단어 벡터를 보고 주변 단어 벡터를 예측하도록 학습

### 주제 2: Sequential Model
#### RNN
- 시간의 흐름에 따른 Sequence가 Input으로 차례차례 들어온다
- Hidden state가 이전 정보들을 누적해서 담고 있다
- Vanishing Gradient 때문에 Long-term dependency 학습이 어렵다

#### LSTM
- Input gate, Forget gate를 통해 어떤 정보를 잊을지 고른다
- Cell state를 추가로 도입, 오래되면 잊는 게 아니라 중요성이 떨어지는 것을 잊는다
- Long-term dependency를 좀 더 잘 파악한다

### 주제 4: Text CNN
- aaa

### 주제 5: GAN
- aaa

### 주제 6: Transformer
- aaa

## 오늘의 도전 과제와 해결 방법
- 도전 과제 1: aa

## 오늘의 회고
- aa

## 참고 자료 및 링크
- aa

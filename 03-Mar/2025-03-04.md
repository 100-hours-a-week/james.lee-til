# 날짜: 2025-03-04

## 새로 배운 내용
### 주제 1: 기초
- Architecture란 레이어의 구성, 입출력 방식, 연결 방식 등 모델의 구조를 뜻한다
- 모델 파일은 학습으로 찾아낸 최적 Weight와 Bias들의 집합이다
- Low / High level feature: 이미지의 경우 선 - 사람 얼굴 등
- Accuracy: 이진 분류는 약 90%, 다중 분류는 약 80%면 유의미한 성능

### 주제 2: Pre-training
- 사전 학습이 되어있는 Model을 가져오면 시간을 절약할 수 있다
- Low Feature 부분은 Feature extractor로 활용한다
- High feature 부분은 Fine-tuning하여 새로운 Task에 적용
- 이렇게 Pre-trained model을 새로운 Task에 사용하는 것을 Transfer learning이라 한다

### 주제 3: VGG16
- Filter size를 3x3으로 고정해, Layer 수를 16까지 늘릴 수 있었다
- ImageNet으로 Pre-training 했으며, Parameter 수는 138M으로 많다
- ResNet보다 가벼워 토이프로젝트에 경우에 따라 쓸 수도

### 주제 4: ResNet
- 이전 층의 정보를 연결하는 Skip connection이 존재
- 이 덕분에 Layer 개수를 크게 늘리고도 Vanishing gradient를 해결 가능

## 오늘의 도전 과제와 해결 방법
- 도전 과제 1: 미니퀘스트 수행
- 도전 과제 2: Porting(tf->torch로 프레임워크 변경)

## 오늘의 회고
- 이론은 알아도 실제 미니퀘스트를 해보니 역시 성능이 떨어졌다
- 성능을 높이는 방법에 대해 배우고 싶다

## 참고 자료 및 링크
- [미니퀘스트 - MNIST](https://colab.research.google.com/drive/1wrH9nGsbd2x-1yBnhz0t0Xre_rFvT2ya?usp=drive_link)
- [미니퀘스트 - CIFAR10](https://colab.research.google.com/drive/135o8lyNBFoM-Z0t_LtQzDq0HJPkI0TDp?usp=drive_link)
